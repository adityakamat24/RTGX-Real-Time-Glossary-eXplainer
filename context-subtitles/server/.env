# Local LLM configuration
OLLAMA_URL=http://127.0.0.1:11434/api/generate
OLLAMA_MODELS=gemma3:12b,qwen3:4b
# Custom model storage location
OLLAMA_MODELS_DIR=D:\cse_518_project\models
# Fallback to HF if needed
HF_TOKEN=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
HF_MODELS=deepseek-ai/DeepSeek-V3-0324